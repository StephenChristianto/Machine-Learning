{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ba8b5a",
   "metadata": {},
   "source": [
    "# Bag of Words & Stop Word Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a8730",
   "metadata": {},
   "source": [
    "Bag of Words menyederhanakan representasi text sebagai sekumpulan kata serta mengabaikan grammar dan posisi tiap kata pada kalimat. Text akan dikonversi menjadi lowercase dan tanda baca akan diabaikan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa7a02",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907645b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distribution include the Linux Kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus= [\n",
    "          'Linux has been around since the mid-1990s.',\n",
    "          'Linux distribution include the Linux Kernel.',\n",
    "          'Linux is one of the most prominent open-source software.'\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acfee0",
   "metadata": {},
   "source": [
    "# Bag of Words model dengan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba3c0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_x = vectorizer.fit_transform(corpus).todense()#menkonfersikan hasil fit_transform dari objek vectorizer menjadi dua dimensi\n",
    "vectorized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854f2d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990s',\n",
       " 'around',\n",
       " 'been',\n",
       " 'distribution',\n",
       " 'has',\n",
       " 'include',\n",
       " 'is',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'most',\n",
       " 'of',\n",
       " 'one',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'since',\n",
       " 'software',\n",
       " 'source',\n",
       " 'the']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c1dc1",
   "metadata": {},
   "source": [
    "# Euclidean Distance untuk mengukur kedekatan/kemiripan antar dokumen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91011b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2: [[3.16227766]]\n",
      "Jarak dokumen 1 dan 3: [[3.74165739]]\n",
      "Jarak dokumen 2 dan 3: [[3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "for i in range(len(vectorized_x)):\n",
    "    for j in range (i, len(vectorized_x)):\n",
    "        if i==j:\n",
    "            continue \n",
    "        jarak = euclidean_distances(vectorized_x[i], vectorized_x[j])\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1}: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cae463",
   "metadata": {},
   "source": [
    "# Stop Word Filtering pada text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b52325",
   "metadata": {},
   "source": [
    "Stop Word Filtering berfungsi menyederhanakan representasi text dengan mengabaikan beberapa kata seperti determiners (the, a, an), auxiliary verbs (do, be, will), dan prepositions (on, in, at)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997ad25",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f612d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distribution include the Linux Kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf21426",
   "metadata": {},
   "source": [
    "# Stop Word Filtering dengan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe6cdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english') #melakukan stop word filtering untuk bahasa inggris\n",
    "vectorized_x = vectorizer.fit_transform(corpus).todense()#menkonfersikan hasil fit_transform dari objek vectorizer menjadi dua dimensi\n",
    "vectorized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b67e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990s',\n",
       " 'distribution',\n",
       " 'include',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'software',\n",
       " 'source']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e368f",
   "metadata": {},
   "source": [
    "# Mengenal TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba08cc",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency) merupakan salah satu metode statistik yang digunakan untuk mengukur seberapa penting suatu kata terhadap suatu dokumen tertentu dari sekumpulan dokumen atau corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603526fe",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6401ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the house had a tiny mouse',\n",
       " 'the cat saw the mouse',\n",
       " 'the mouse ran away from the house',\n",
       " 'the cat finaly ate the mouse',\n",
       " 'the end of the mouse story']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['the house had a tiny mouse',\n",
    "         'the cat saw the mouse',\n",
    "         'the mouse ran away from the house',\n",
    "         'the cat finaly ate the mouse',\n",
    "         'the end of the mouse story']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6945a",
   "metadata": {},
   "source": [
    "# TF-IDF Weights dengan TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f9bf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t0.3477147117091919\n",
      "  (0, 10)\t0.7297183669435993\n",
      "  (0, 5)\t0.5887321837696324\n",
      "  (1, 8)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 6)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 7)\t0.5894630806320427\n",
      "  (2, 6)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 6)\t0.2808823162882302\n",
      "  (4, 9)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 6)\t0.3193023297639811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english') \n",
    "response = vectorizer.fit_transform(corpus)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a450df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ate',\n",
       " 'away',\n",
       " 'cat',\n",
       " 'end',\n",
       " 'finaly',\n",
       " 'house',\n",
       " 'mouse',\n",
       " 'ran',\n",
       " 'saw',\n",
       " 'story',\n",
       " 'tiny']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4e87ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.58873218, 0.34771471, 0.        , 0.        , 0.        ,\n",
       "         0.72971837],\n",
       "        [0.        , 0.        , 0.58873218, 0.        , 0.        ,\n",
       "         0.        , 0.34771471, 0.        , 0.72971837, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.58946308, 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.28088232, 0.58946308, 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.58946308, 0.        , 0.4755751 , 0.        , 0.58946308,\n",
       "         0.        , 0.28088232, 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.67009179, 0.        ,\n",
       "         0.        , 0.31930233, 0.        , 0.        , 0.67009179,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7899f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finaly</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.319302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ran</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              D1        D2        D3        D4        D5\n",
       "ate     0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "away    0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "cat     0.000000  0.588732  0.000000  0.475575  0.000000\n",
       "end     0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "finaly  0.000000  0.000000  0.000000  0.589463  0.000000\n",
       "house   0.588732  0.000000  0.475575  0.000000  0.000000\n",
       "mouse   0.347715  0.347715  0.280882  0.280882  0.319302\n",
       "ran     0.000000  0.000000  0.589463  0.000000  0.000000\n",
       "saw     0.000000  0.729718  0.000000  0.000000  0.000000\n",
       "story   0.000000  0.000000  0.000000  0.000000  0.670092\n",
       "tiny    0.729718  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(response.todense().T,\n",
    "                 index=vectorizer.get_feature_names(),\n",
    "                 columns=[f'D{i+1}' for i in range (len(corpus))])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36aab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
